{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e75f49",
   "metadata": {},
   "source": [
    "# Actividad 4.4.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4d81f",
   "metadata": {},
   "source": [
    "## A (40 puntos) Funciones de evaluación:\n",
    "\n",
    "Este punto es comparando directamente las listas de clase y de hipótesis, no utilices funciones preestablecidas que calculen las métricas o la matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb61e8",
   "metadata": {},
   "source": [
    "1. Genera una función que reciba como parámetros una clase objetivo, la lista de clases reales y de clases asignadas por un modelo, imprima la matriz de confusión y retorne los valores de TP, TN, FP y FN. Esta función recibe 3 parámetros y retorna 4 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6af28cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>245</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.851</td>\n",
       "      <td>28</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>106</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.466</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.181</td>\n",
       "      <td>29</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.580</td>\n",
       "      <td>24</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     3   158    76    36   245  31.6  0.851   28  tested_positive\n",
       "1     1   117    60    23   106  33.8  0.466   27  tested_negative\n",
       "2     1   107    50    19     0  28.3  0.181   29  tested_negative\n",
       "3     1    90    62    12    43  27.2  0.580   24  tested_negative\n",
       "4     2    88    58    26    16  28.4  0.766   22  tested_negative"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('diabetes (1).csv')\n",
    "df.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1fcfc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_matriz_confusion_manual(clase_objetivo, reales, asignadas):\n",
    "    # Inicializar contadores\n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    # Calcular valores de la matriz de confusión\n",
    "    for r, a in zip(reales, asignadas):\n",
    "        if r == clase_objetivo and a == clase_objetivo:\n",
    "            TP += 1\n",
    "        elif r == clase_objetivo and a != clase_objetivo:\n",
    "            FN += 1\n",
    "        elif r != clase_objetivo and a == clase_objetivo:\n",
    "            FP += 1\n",
    "        elif r != clase_objetivo and a != clase_objetivo:\n",
    "            TN += 1\n",
    "    \n",
    "    # Imprimir la matriz de confusión\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(f\"[[{TP}, {FN}]\\n [{FP}, {TN}]]\")\n",
    "    \n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95b06035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3, 3]\n",
      " [5, 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 4, 5, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables de la clase\n",
    "Clase_objetivo = 'Neg'\n",
    "real = pd.Series(['Pos', 'Pos', 'Neg', 'Neg', 'Neg', 'Pos', 'Pos', 'Pos', 'Pos', 'Pos', 'Neg', 'Pos', 'Neg', 'Pos', 'Neg'])\n",
    "hipotesis = ['Pos', 'Neg', 'Neg', 'Neg', 'Pos', 'Pos', 'Pos', 'Neg', 'Neg', 'Pos', 'Pos', 'Neg', 'Neg', 'Neg', 'Pos']\n",
    "\n",
    "# Llamar a la función con las variables definidas\n",
    "calcular_matriz_confusion_manual(Clase_objetivo, real, hipotesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9a0d2",
   "metadata": {},
   "source": [
    "2. Genera una función que reciba los valores de TP, TN, FP y FN y retorne los valores de precision, recall y F1. Esta función recibe 4 parámetros y retorna 3 valores. Puedes probar tus funciones con los datos del ejercicio realizado en clase:\n",
    "\n",
    "`Clase_objetivo='Neg'\n",
    "real=pd.Series(['Pos','Pos','Neg','Neg','Neg','Pos','Pos','Pos','Pos','Pos','Neg','Pos','Neg','Pos','Neg'])\n",
    "hipotesis=['Pos','Neg','Neg','Neg','Pos','Pos','Pos','Neg','Neg','Pos','Pos','Neg','Neg','Neg','Pos']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3178c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3, 3]\n",
      " [5, 4]]\n",
      "Precision: 0.375000,  Recall: 0.500000, F1: 0.428571\n",
      "Precision: 0.375000,  Recall: 0.500000, F1: 0.428571\n"
     ]
    }
   ],
   "source": [
    "# Calcular precision, recall y F1\n",
    "def calcular_metricas(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Obtener los valores de TP, TN, FP, FN de la función anterior\n",
    "tp, tn, fp, fn = calcular_matriz_confusion_manual(Clase_objetivo, real, hipotesis)\n",
    "\n",
    "# Probar la función con los datos obtenidos\n",
    "precision, recall, f1 = calcular_metricas(tp, fp, fn)\n",
    "print(\"Precision: %f,  Recall: %f, F1: %f\" % (precision, recall, f1))\n",
    "print(\"Precision: %f,  Recall: %f, F1: %f\" % (precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5386ea7",
   "metadata": {},
   "source": [
    "## B (30 puntos) Generar modelos:\n",
    "\n",
    "3. Genera al menos 5 modelos utilizando el conjunto de datos \"diabetes\" y el clasificador de árbol de decisión. Puedes cambiar el nivel de profundidad, instancias por hoja o el porcentaje de instancias para evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14f6b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy: 0.7922\n",
      "Model 2 Accuracy: 0.7489\n",
      "Model 3 Accuracy: 0.7576\n",
      "Model 4 Accuracy: 0.7489\n",
      "Model 5 Accuracy: 0.7619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Preparación de los datos \n",
    "# Ponemos outcome como el target \n",
    "X = df.drop(columns=['class'])  \n",
    "y = df['class']\n",
    "\n",
    "# Datos de entrenamiento y de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hacemos 5 modelos de clasificación \n",
    "models = [\n",
    "    DecisionTreeClassifier(max_depth=3),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    DecisionTreeClassifier(min_samples_leaf=5),\n",
    "    DecisionTreeClassifier(min_samples_split=10),\n",
    "    DecisionTreeClassifier(max_depth=4, min_samples_leaf=3)\n",
    "]\n",
    "\n",
    "# Entrenar los modelos \n",
    "model_results = []\n",
    "for i, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_results.append((f\"Model {i+1}\", accuracy))\n",
    "    print(f\"Model {i+1} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa65341",
   "metadata": {},
   "source": [
    "## C (30 puntos) Evaluar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5150800",
   "metadata": {},
   "source": [
    "5. Calcula la exactitud de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e17c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156a46f8",
   "metadata": {},
   "source": [
    "4. Utiliza las funciones generadas en el punto anterior para evaluar cada uno de los modelos generado. Imprime las matrices y resultados de las métricas por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "979c19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Matriz de Confusión:\n",
      "[[0, 0]\n",
      " [0, 231]]\n",
      "Accuracy: 0.7922, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "Model 2:\n",
      "Matriz de Confusión:\n",
      "[[0, 0]\n",
      " [0, 231]]\n",
      "Accuracy: 0.7489, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "Model 3:\n",
      "Matriz de Confusión:\n",
      "[[0, 0]\n",
      " [0, 231]]\n",
      "Accuracy: 0.7576, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "Model 4:\n",
      "Matriz de Confusión:\n",
      "[[0, 0]\n",
      " [0, 231]]\n",
      "Accuracy: 0.7489, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n",
      "Model 5:\n",
      "Matriz de Confusión:\n",
      "[[0, 0]\n",
      " [0, 231]]\n",
      "Accuracy: 0.7619, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar cada modelo y mostrar resultados\n",
    "for i, (model_name, accuracy) in enumerate(model_results):\n",
    "    # Predecir con el modelo actual\n",
    "    y_pred = models[i].predict(X_test)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    print(f\"{model_name}:\")\n",
    "    tp, tn, fp, fn = calcular_matriz_confusion_manual(Clase_objetivo, y_test, y_pred)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    precision, recall, f1 = calcular_metricas(tp, fp, fn)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02f59b",
   "metadata": {},
   "source": [
    "6. Redacta un párrafo donde menciones qué modelo obtuvo mayor: Exactitud, precision y recall (¿Fue el mismo?,¿Por qué?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65619a53",
   "metadata": {},
   "source": [
    "El modelo que obtuvo la mayor exactitud fue el Modelo 1 con un valor de 0.7922. Sin embargo, al evaluar las métricas de precisión y recall, es posible que otros modelos hayan tenido un mejor desempeño en estas métricas específicas dependiendo de cómo se distribuyeron los valores de TP, TN, FP y FN. Esto ocurre porque la exactitud mide el porcentaje total de predicciones correctas, mientras que la precisión y el recall se enfocan en el desempeño sobre clases específicas, lo que puede variar según el balance de clases en los datos y los parámetros del modelo. Por lo tanto, no necesariamente el modelo con mayor exactitud será el mismo que tenga la mejor precisión o recall, ya que estas métricas evalúan aspectos diferentes del desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac74aaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
